{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import random\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import Imputer\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('allPatients.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('Classes',axis=1)\n",
    "features = X.columns\n",
    "X.replace(to_replace='?', value = 'NaN', inplace=True)\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "X=imp.fit_transform(X)\n",
    "Y = df['Classes']\n",
    "X = pd.DataFrame(X,columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features=100, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, criterion = 'entropy', max_features = 100)\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqFeatures = np.zeros(shape=(8560), dtype=int)\n",
    "for tree in clf:\n",
    "    for i in tree.tree_.feature:\n",
    "        if i !=-2:\n",
    "            freqFeatures[i] = freqFeatures[i]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5248, 7369, 1577, 4820, 5182, 2221, 2606, 6535, 3756, 7413, 4668,\n",
       "       8064, 8035, 4081, 5125, 4100,  616, 5640, 3418,  429, 3272, 5991,\n",
       "       3745, 2410, 1812, 4470, 2017, 7175, 2991, 6036, 2282, 2485, 6062,\n",
       "       1409,  683, 6258, 6557, 2435,  604, 5327, 6115, 4561,  352, 4920,\n",
       "       7284, 3817, 6841, 5323,  802, 2855, 6737,  520, 7754, 2734, 7247,\n",
       "       6717, 1630, 7549, 6796, 3109, 5708, 2159, 4072, 4658, 3192, 6755,\n",
       "        320, 3789, 6361,  177, 5440, 1016, 5948, 1665, 1025,  416, 5978,\n",
       "       2831, 1671,  974, 3633, 3643, 8512, 1586, 7324, 1573, 4864, 4127,\n",
       "       3650, 2096, 5892, 8338, 1454, 3388, 1832, 6536, 5486,  446, 4446,\n",
       "       5506, 8330, 3822, 6364, 5497, 2153, 3436, 8320, 1305, 1306, 4434,\n",
       "       8218, 1777, 7582, 5584, 7540, 7478, 3401, 6481,  421, 6489,  411,\n",
       "       5053, 1553, 1805, 2430, 6496, 3387, 4507, 7537, 3408, 5529, 2194,\n",
       "       7492, 7495, 2671, 6532, 7398, 1545, 5076, 1814, 1349,  125, 2271,\n",
       "       5850, 1903, 7897, 4775, 5996, 3635, 3638, 4880, 4758, 3138, 7859,\n",
       "        207, 7856, 6030, 1042, 7834, 4740, 2752,  216, 4862, 2369, 1432,\n",
       "       2769, 2175,  232, 3593, 5905, 3599, 3604, 2073, 4804, 2094, 7920,\n",
       "       5876,  246, 5874, 5961, 4855,  250, 6055, 3679, 6079, 7798, 8136,\n",
       "       1163, 8140, 6221, 2164,  346, 8150, 6247, 6254, 6271, 2234, 1517,\n",
       "       6305, 1357])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top200Features = abs(freqFeatures).argsort()[::-1][:200]\n",
    "pd.DataFrame(top200Features[:100]).to_csv('top100Features.csv')\n",
    "featureSelectedX = X.ix[:,top200Features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getClusterGroups(labels,data,k):\n",
    "    d = dict(); \n",
    "    for i in range(0,k):\n",
    "        d[\"cluster\"+str(i)] =  data.ix[np.nonzero(labels==i)]\n",
    "    return d\n",
    "\n",
    "def getDistances(clusters,distanceMeasure):\n",
    "    distDict = dict()\n",
    "    for cluster1 in itertools.combinations(clusters, 2):\n",
    "        dist = cdist(clusters[cluster1[0]],clusters[cluster1[1]], distanceMeasure)\n",
    "        n,m = dist.shape\n",
    "        distDict[cluster1[0]+\" \" +cluster1[1] + \" Single Link\"] = np.nanmin(dist)\n",
    "        distDict[cluster1[0]+\" \" +cluster1[1] + \" complete Link\"] = np.nanmax(dist)\n",
    "        dist = np.nan_to_num(dist)\n",
    "        distDict[cluster1[0]+\" \" + cluster1[1] + \" average\"] = sum(sum(dist))/(n*m)\n",
    "        distDict[cluster1[0] + \" \"+ cluster1[1] + \" centriod\"] = np.amax(cdist(pd.DataFrame(clusters[cluster1[0]].mean()).transpose(),pd.DataFrame(clusters[cluster1[1]].mean()).transpose(),distanceMeasure))\n",
    "    return distDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimatorsEuclidean = {'k_means_euclidean_2': KMeans(n_clusters=2).fit(featureSelectedX),\n",
    "              'k_means_euclidean_3': KMeans(n_clusters=3).fit(featureSelectedX),\n",
    "              'k_means_euclidean_4': KMeans(n_clusters=4).fit(featureSelectedX)}\n",
    "\n",
    "def new_euclidean_distances(X, Y=None, Y_norm_squared=None, squared=False): \n",
    "    return cosine_similarity(X,Y)\n",
    "\n",
    "# monkey patch (ensure cosine dist function is used)\n",
    "KMeans.euclidean_distances = new_euclidean_distances \n",
    "estimatorsDot = {'k_means_dot_2': KMeans(n_clusters=2).fit(featureSelectedX),\n",
    "              'k_means_dot_3': KMeans(n_clusters=3).fit(featureSelectedX),\n",
    "              'k_means_dot_4': KMeans(n_clusters=4).fit(featureSelectedX)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cluster in estimatorsEuclidean:\n",
    "    k = len(np.unique(estimatorsEuclidean[cluster].labels_))\n",
    "    groups = getClusterGroups(estimatorsEuclidean[cluster].labels_,featureSelectedX,len(np.unique(estimatorsEuclidean[cluster].labels_)))\n",
    "    dist = getDistances(groups,'euclidean')\n",
    "    pd.DataFrame([dist]).transpose().to_csv('ResultsEuclideanK({0}).csv'.format(k))\n",
    "for cluster in estimatorsDot:\n",
    "    k = len(np.unique(estimatorsDot[cluster].labels_))\n",
    "    groups = getClusterGroups(estimatorsDot[cluster].labels_,featureSelectedX,k)\n",
    "    dist = getDistances(groups,'cosine')\n",
    "    pd.DataFrame([dist]).transpose().to_csv('ResultsDotK({0}).csv'.format(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
